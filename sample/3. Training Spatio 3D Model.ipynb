{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfc00806-ebbc-4cf1-b59e-39763ff96dae",
   "metadata": {},
   "source": [
    "# API需求\n",
    "\n",
    "\n",
    "1. Generate Example numpy Data example_np: in size of batch x m x n x t x c, output is a float number (range from 0 to 3000)\n",
    "{randomly get value from -1 to 1}\n",
    "\n",
    "Example: \n",
    "function generate_example_np():\n",
    " return numpy array\n",
    "example_np=generate_example_np()\n",
    "\n",
    " \n",
    " \n",
    "2. 我有一个非常大的数据集，in size of q x m x n x t x c. q代表样本数量，帮我构思一种最有效率的存储改数据集的方式。\n",
    "Generate Example numpy Data {randomly get value from -1 to 1} 并且写入中\n",
    "save_dir=r\"C:\\Datasets\\Zhejiang20-23RS\\temp_training\"\n",
    "\n",
    "3. \n",
    "Make a function generate_loader()\n",
    "{randomly split training and test data of 80% - 20%}\n",
    "\n",
    "Example: \n",
    "if data is numpy array function generate_loader(example_np):\n",
    " return: (lightning dataloader) train_loader, test_loader\n",
    "\n",
    " if input is string, 给定save_dir， 读取数据\n",
    "\n",
    " 然后帮我写一个测试代码\n",
    "\n",
    " \n",
    "3. Make a regression model by using lightning.\n",
    "input: batch x c x w x h x t   \n",
    "output: a float number\n",
    "\n",
    "class SpatioTemporalModel\n",
    " ST_attention \n",
    " backbone=resnet18 feature\n",
    " \n",
    " \n",
    " output=st(input) \n",
    " output=backbone(output) \n",
    " then make output be a float number\n",
    " \n",
    "class ST_attention：\n",
    "    spatial_attention  # hxwx1\n",
    "    temporal_attention # 1x1xt\n",
    "    st[hxwxt]=sigmoid(spatial_attention x (elementwise multiply) temporal_attention) \n",
    "\n",
    "    output=st(input)\n",
    "\n",
    "\n",
    "Help me annotate them in style of Google coding python doc string WITH type hinting\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47da0eab-242b-4d51-95b2-2e5cf8818b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"C:/Users/isxzl/OneDrive/Code/AutoGeo\")\n",
    "from tqdm import tqdm \n",
    "from sample.unit_test import generate_example, generate_large_dataset\t\n",
    "from sample.dataset import generate_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beeb6236-6bc5-4044-8650-01f8ed001063",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test 1\n",
    "q, m, n, t, c = 5000, 10, 20, 20, 20  # Example dimensions\n",
    "test_data_0d = generate_example((q, c))\n",
    "test_data_1d = generate_example((q, t, c))\n",
    "test_data_2d = generate_example((q, m, n, c))\n",
    "test_data_3d = generate_example((q, m, n, t, c))\n",
    "\n",
    "# Example to get data in different formats\n",
    "numpy_data, numpy_labels = generate_example((q, c))  # Default numpy\n",
    "tensor_data, tensor_labels = generate_example((q, c), type=\"tensor\")\n",
    "dataset = generate_example((q, c), type=\"dataset\")\n",
    "dataloader = generate_example((q, c), type=\"dataloader\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b84b8c2-6b23-4399-a6f9-38180b1fa327",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test 2\n",
    "save_dir = \"C:/Datasets/Zhejiang20-23RS/temp_training\"\n",
    "save_dir=generate_large_dataset(q, m, n, t, c, save_dir)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Generate or load datasets\n",
    "train_dataset, test_dataset = generate_datasets(save_dir)\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Print the length of the test dataset\n",
    "print(len(test_dataset))\n",
    "\n",
    "# Example usage of the test_loader\n",
    "for x,y in tqdm(test_loader):\n",
    "    # Process your training data here\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2032b752-fc69-4c95-8eed-e67298f5fb3a",
   "metadata": {},
   "source": [
    "# 0D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c192317-859a-42d6-abb4-ff57001e1531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(0)  # For reproducibility\n",
    "x = np.random.uniform(-1, 1, (1000,10))  # 1000 samples\n",
    "y = np.random.uniform(0, 3000, 1000)  # Target values in the range 0 to 3000\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "x_tensor = torch.tensor(x, dtype=torch.float32).unsqueeze(-1)  # Adding an extra dimension for compatibility\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# Create a PyTorch dataset and dataloader\n",
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "train_loader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "# Define the ANN model\n",
    "class RegressionModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(10, 64),  # Input layer to first hidden layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),  # First hidden layer to second hidden layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),  # Second hidden layer to third hidden layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)  # Third hidden layer to output layer\n",
    "        )\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y.unsqueeze(1))\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters(), lr=0.0005)\n",
    "\n",
    "# Define PyTorch Lightning trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=5,\n",
    "    callbacks=[EarlyStopping(monitor='train_loss', patience=50, min_delta=1e-4)]\n",
    ")\n",
    "\n",
    "# Initialize the model\n",
    "model = RegressionModel()\n",
    "\n",
    "model(x_tensor[:24])\n",
    "# Train the model\n",
    "trainer.fit(model, train_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c5395c-4bc4-4486-a711-19987aca624d",
   "metadata": {},
   "source": [
    "# 1D KNN,\n",
    "C x 1 x 1 x 1\n",
    "\n",
    "\n",
    "3. Make a regression model by using lightning.\n",
    "TEST BY USING np.random.uniform(-1, 1,  )\n",
    "\n",
    "Common setting\tLooked-back steps\t12\n",
    "\tOptimizer\tAdam\n",
    "\tLoss function\tMSE\n",
    "\tLearning rate\t0.0005\n",
    "\tEpoch\t100\n",
    "\tEarly Stopping patience (delta)\t50 (10-4)\n",
    "\tBatch size\t128\n",
    "  \n",
    "\n",
    "Input is 1d.  batch x t x c, output is a float number (range from 0 to 3000) \n",
    "    Layer 3 Layer\n",
    "\tKernel size\t9\n",
    "\tChannel size\t>9 \n",
    "    for outher parameter make it by yourself according to your experience.\n",
    " x 1\n",
    "knn, lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57de0b9a-671d-451d-b7d2-841148cfbe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "class CNNRegressionModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(CNNRegressionModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=10, out_channels=16, kernel_size=9, padding=4)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=9, padding=4)\n",
    "        self.conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=9, padding=4)\n",
    "        self.fc1 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = torch.mean(x, 2)  # Global Average Pooling\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters(), lr=0.0005)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "# Data preparation\n",
    "np.random.seed(42)\n",
    "x = np.random.uniform(-1, 1, (1000, 12, 10))  # 1000 samples, 10 input channels, 12 time steps\n",
    "y = np.random.uniform(0, 3000, (1000, 1))  # Corresponding targets\n",
    "\n",
    "x_tensor = torch.tensor(x, dtype=torch.float32).transpose(1, 2)  # Adjust dimensions for Conv1d (batch, channels, length)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "train_size = int(len(dataset) * 0.8)\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128)\n",
    "\n",
    "# Initialize the PyTorch Lightning model\n",
    "model = CNNRegressionModel()\n",
    "\n",
    "# Trainer setup\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    callbacks=[pl.callbacks.EarlyStopping(monitor='train_loss', patience=50, min_delta=1e-4)],\n",
    "    #progress_bar_refresh_rate=20\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38dd2f0-15d0-4314-8277-14e321d28c84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8595adba-ed56-49f9-a8c6-f2e5a96a64ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67d9361c-0575-451c-9742-faa080e148da",
   "metadata": {},
   "source": [
    "# 2D CNN\n",
    "C x 5 x 5 x 1 \n",
    "\n",
    "3. Make a regression model by using lightning.\n",
    "TEST BY USING np.random.uniform(-1, 1,  )\n",
    "\n",
    "Common setting\tLooked-back steps\t12\n",
    "\tOptimizer\tAdam\n",
    "\tLoss function\tMSE\n",
    "\tLearning rate\t0.0005\n",
    "\tEpoch\t100\n",
    "\tEarly Stopping patience (delta)\t50 (10-4)\n",
    "\tBatch size\t128\n",
    " \n",
    " \n",
    "Input is 2d.  batch x m x n x c, output is a float number (range from 0 to 3000) \n",
    "  \n",
    "CNN\tNumber of convolution layers\t4\n",
    "\tKernel size\t3 × 3\n",
    "\tChannel size\tis a parameter to be initialized\n",
    "\tActivation function\tTanh\n",
    "\n",
    "Then test it with 10 epochnh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cd0a4cf-e33d-45c3-a833-cbff51ebd855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "class CNN2DRegression(pl.LightningModule):\n",
    "    def __init__(self, input_channels, output_features=1):\n",
    "        super().__init__()\n",
    "        self.conv_net = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 16, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AdaptiveAvgPool2d(1)  # Global Average Pooling to reduce to 1x1x128\n",
    "        )\n",
    "        self.fc = nn.Linear(128, output_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=x.permute(0, 3, 1, 2)\n",
    "        x = self.conv_net(x)\n",
    "        x = torch.flatten(x, 1)  # Flatten all dimensions except batch\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = nn.MSELoss()(y_hat, y.view(-1, 1))\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.0005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b04b989f-be37-4770-aad2-bd37f9e26b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type       | Params\n",
      "----------------------------------------\n",
      "0 | conv_net | Sequential | 97.4 K\n",
      "1 | fc       | Linear     | 129   \n",
      "----------------------------------------\n",
      "97.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "97.6 K    Total params\n",
      "0.390     Total estimated model params size (MB)\n",
      "C:\\Users\\isxzl\\anaconda3\\envs\\EO\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|███████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 62.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|███████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 48.03it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Assuming m=28, n=28, c=3 for example\n",
    "m, n, c = 28, 28, 3\n",
    "x = np.random.uniform(-1, 1, (1000, m, n, c)).astype(np.float32)\n",
    "y = np.random.uniform(0, 3000, (1000, 1)).astype(np.float32)\n",
    "\n",
    "x_tensor = torch.tensor(x)\n",
    "y_tensor = torch.tensor(y)\n",
    "\n",
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "train_loader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "# Initialize the model\n",
    "model = CNN2DRegression(input_channels=c)\n",
    "\n",
    "# Trainer setup\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    callbacks=[EarlyStopping(monitor='train_loss', patience=50, min_delta=1e-4)],\n",
    "    #progress_bar_refresh_rate=20,\n",
    "    logger=False  # Disable logging for simplicity\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model, train_loader)\n",
    "#model(x_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96efbf8d-9e0d-4324-810e-3073b53bc619",
   "metadata": {},
   "source": [
    "# 3D CNN\n",
    "C x 5 x 5 x 1\n",
    "\n",
    "3. Make a regression model by using lightning.\n",
    "TEST BY USING np.random.uniform(-1, 1,  )\n",
    "\n",
    "Common setting\tLooked-back steps\t12\n",
    "\tOptimizer\tAdam\n",
    "\tLoss function\tMSE\n",
    "\tLearning rate\t0.0005\n",
    "\tEpoch\t100\n",
    "\tEarly Stopping patience (delta)\t50 (10-4)\n",
    "\tBatch size\t128\n",
    "\n",
    "\n",
    "Input is 3d.  batch x m x n x t x c, output is a float number (range from 0 to 3000)\n",
    " \n",
    "\n",
    "\n",
    "CNN\tNumber of convolution layers\t4\n",
    "\tKernel size\t3 × 3 x 3\n",
    "\tChannel size\t8 or 10\n",
    "\tActivation function\tTanh\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33b28df4-3db8-42ab-84f6-13e68e5b70dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "class CNN3DRegression(pl.LightningModule):\n",
    "    def __init__(self, input_channels, output_features=1):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv3d(input_channels, 8, kernel_size=(3, 3, 3), padding=(1, 1, 1)),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv3d(8, 16, kernel_size=(3, 3, 3), padding=(1, 1, 1)),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv3d(16, 32, kernel_size=(3, 3, 3), padding=(1, 1, 1)),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv3d(32, 64, kernel_size=(3, 3, 3), padding=(1, 1, 1)),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.fc = nn.Linear(64, output_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = nn.MSELoss()(y_hat, y.view(-1, 1))\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.0005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb23347f-ef4b-4654-ad02-631f9bb055ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "\n",
    "# Example dimensions\n",
    "m, n, t, c = 8, 8, 12, 8  # Adjust dimensions as needed\n",
    "x = np.random.uniform(-1, 1, (1000, c, t, m, n)).astype(np.float32)  # Synthetic data\n",
    "y = np.random.uniform(0, 3000, (1000, 1)).astype(np.float32)  # Target output\n",
    "\n",
    "x_tensor = torch.tensor(x)\n",
    "y_tensor = torch.tensor(y)\n",
    "\n",
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "train_loader = DataLoader(dataset, batch_size=128, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c29f33f-a9f1-4ed6-86d0-261f1eeb9cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\isxzl\\anaconda3\\envs\\EO\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:639: Checkpoint directory C:\\Users\\isxzl\\OneDrive\\Code\\AutoGeo\\sample\\checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type              | Params\n",
      "------------------------------------------------------\n",
      "0 | layer1          | Sequential        | 1.7 K \n",
      "1 | layer2          | Sequential        | 3.5 K \n",
      "2 | layer3          | Sequential        | 13.9 K\n",
      "3 | layer4          | Sequential        | 55.4 K\n",
      "4 | global_avg_pool | AdaptiveAvgPool3d | 0     \n",
      "5 | fc              | Linear            | 65    \n",
      "------------------------------------------------------\n",
      "74.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "74.5 K    Total params\n",
      "0.298     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35:  25%|██████████████████▌                                                       | 2/8 [00:00<00:00, 68.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isxzl\\anaconda3\\envs\\EO\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "model = CNN3DRegression(input_channels=c)\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    callbacks=[EarlyStopping(monitor='train_loss', patience=50, min_delta=1e-4)],\n",
    "    #progress_bar_refresh_rate=20,\n",
    "    logger=False  # To simplify output for this example\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea737ab-a28b-424f-b169-0cf747316dba",
   "metadata": {},
   "source": [
    "# 4D CNN\n",
    "C x 5 x 5 x 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b5aa15-1721-446c-95e4-df714cd80b16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
